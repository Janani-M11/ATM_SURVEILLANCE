# ðŸ”¬ Detection Algorithms - Detailed Technical Specifications

This document continues from APPLICATION_FLOW_AND_ARCHITECTURE.md and provides detailed step-by-step flows for each detection algorithm.

---

## Table of Contents
- [4.2 Helmet Detection Algorithm](#42-helmet-detection-algorithm)
- [4.3 Face Cover Detection Algorithm](#43-face-cover-detection-algorithm)
- [4.4 Loitering Detection Algorithm](#44-loitering-detection-algorithm)
- [4.5 Posture Detection Algorithm](#45-posture-detection-algorithm)
- [5. Database Queries & Data Flow](#5-database-queries--data-flow)

---

## 4.2 Helmet Detection Algorithm (Detailed Flow)

```
INPUT: Frame (640x480 BGR image)
  â”‚
  â”œâ”€â–º Step 0: Pre-check
  â”‚    â”œâ”€â–º Run people detection first
  â”‚    â””â”€â–º If no people detected: RETURN (False, 0.0)
  â”‚
  â”œâ”€â–º Step 1: Run 5 Different Detection Methods
  â”‚    â”‚
  â”‚    â”œâ”€â–º Method 1: Multi-Color Space Analysis (Weight: 25%)
  â”‚    â”‚    â”œâ”€â–º Convert frame to 3 color spaces:
  â”‚    â”‚    â”‚    - HSV (Hue-Saturation-Value)
  â”‚    â”‚    â”‚    - LAB (Lightness-A-B)
  â”‚    â”‚    â”‚    - YCrCb (Luma-Chroma)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º For HSV color space:
  â”‚    â”‚    â”‚    â”œâ”€â–º Apply 9 different helmet color ranges:
  â”‚    â”‚    â”‚    â”‚    1. Black: [0,0,0] to [180,255,50]
  â”‚    â”‚    â”‚    â”‚    2. White: [0,0,200] to [180,30,255]
  â”‚    â”‚    â”‚    â”‚    3. Dark Blue: [100,50,20] to [130,255,100]
  â”‚    â”‚    â”‚    â”‚    4. Light Blue: [90,30,100] to [110,255,255]
  â”‚    â”‚    â”‚    â”‚    5. Red (2 ranges): [0,50,50] to [10,255,255]
  â”‚    â”‚    â”‚    â”‚                   and [170,50,50] to [180,255,255]
  â”‚    â”‚    â”‚    â”‚    6. Yellow: [20,100,100] to [35,255,255]
  â”‚    â”‚    â”‚    â”‚    7. Orange: [10,100,100] to [25,255,255]
  â”‚    â”‚    â”‚    â”‚    8. Green: [35,50,50] to [85,255,255]
  â”‚    â”‚    â”‚    â”‚    9. Gray: [0,0,50] to [180,30,200]
  â”‚    â”‚    â”‚    â”‚
  â”‚    â”‚    â”‚    â”œâ”€â–º Create mask for each color range:
  â”‚    â”‚    â”‚    â”‚    mask = cv2.inRange(hsv, lower_bound, upper_bound)
  â”‚    â”‚    â”‚    â”‚
  â”‚    â”‚    â”‚    â””â”€â–º Combine all masks with bitwise OR:
  â”‚    â”‚    â”‚         combined_mask = mask1 | mask2 | mask3 | ...
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Clean the combined mask:
  â”‚    â”‚    â”‚    â”œâ”€â–º Morphological closing (7x7 ellipse) - fill small holes
  â”‚    â”‚    â”‚    â”œâ”€â–º Morphological opening (7x7 ellipse) - remove noise
  â”‚    â”‚    â”‚    â””â”€â–º Gaussian blur (5x5) - smooth edges
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Find contours in cleaned mask
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º For each contour:
  â”‚    â”‚    â”‚    â”œâ”€â–º If area > 2000 pixels:
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Get bounding box (x, y, w, h)
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Check position: y < frame_height * 0.45 (upper 45%)
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Check aspect ratio: 0.7 <= w/h <= 1.4
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate perimeter
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate circularity = 4*Ï€*area / perimeterÂ²
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º If circularity > 0.5:
  â”‚    â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Fit ellipse to contour
  â”‚    â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate ellipse area = Ï€*(w/2)*(h/2)
  â”‚    â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate fit_ratio = contour_area / ellipse_area
  â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€â–º If fit_ratio > 0.75:
  â”‚    â”‚    â”‚    â”‚    â”‚         â””â”€â–º Helmet detected!
  â”‚    â”‚    â”‚    â”‚    â”‚              confidence = min(0.95, circularity * fit_ratio)
  â”‚    â”‚    â”‚    â”‚    â”‚              RETURN (True, confidence)
  â”‚    â”‚    â”‚    â”‚
  â”‚    â”‚    â”‚    â””â”€â–º If no valid helmet found: RETURN (False, 0.0)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: (helmet_detected_color, confidence_color)
  â”‚    â”‚
  â”‚    â”œâ”€â–º Method 2: Template Matching (Weight: 20%)
  â”‚    â”‚    â”œâ”€â–º Convert frame to grayscale
  â”‚    â”‚    â”œâ”€â–º Enhance contrast using histogram equalization
  â”‚    â”‚    â”œâ”€â–º Use 42 pre-generated helmet templates:
  â”‚    â”‚    â”‚    - 3 types: circle, vertical ellipse, horizontal ellipse
  â”‚    â”‚    â”‚    - 14 sizes each: radius 15-60 pixels (step 5)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º For each template:
  â”‚    â”‚    â”‚    â”œâ”€â–º For each scale [0.5, 0.7, 0.9, 1.0, 1.2, 1.5]:
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Resize template by scale factor
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º If template larger than frame: skip
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º For each matching method [CCOEFF_NORMED, CCORR_NORMED]:
  â”‚    â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º result = matchTemplate(gray, scaled_template, method)
  â”‚    â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Find max match value and location
  â”‚    â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º If match in upper 45% of frame AND value > 0.6:
  â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â””â”€â–º Helmet detected!
  â”‚    â”‚    â”‚    â”‚    â”‚    â”‚         max_confidence = max(max_confidence, match_value)
  â”‚    â”‚    â”‚    â”‚    â”‚
  â”‚    â”‚    â”‚    â”‚    â””â”€â–º Continue with next template/scale
  â”‚    â”‚    â”‚    â”‚
  â”‚    â”‚    â”‚    â””â”€â–º Result: (helmet_detected_template, max_confidence)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: (helmet_detected_template, confidence_template)
  â”‚    â”‚
  â”‚    â”œâ”€â–º Method 3: Circular Hough Transform (Weight: 25%)
  â”‚    â”‚    â”œâ”€â–º Convert to grayscale
  â”‚    â”‚    â”œâ”€â–º Apply Gaussian blur (9x9, sigma=2)
  â”‚    â”‚    â”œâ”€â–º Focus on upper half of frame (where helmets appear)
  â”‚    â”‚    â”œâ”€â–º Run Hough Circle detection with multiple parameter sets:
  â”‚    â”‚    â”‚    For param1 in [50, 70, 100]:  # Edge detection threshold
  â”‚    â”‚    â”‚      For param2 in [25, 30, 35]:  # Circle detection threshold
  â”‚    â”‚    â”‚        circles = HoughCircles(
  â”‚    â”‚    â”‚          upper_half_frame,
  â”‚    â”‚    â”‚          method = HOUGH_GRADIENT,
  â”‚    â”‚    â”‚          dp = 1.2,  # Inverse accumulator resolution ratio
  â”‚    â”‚    â”‚          minDist = 50,  # Minimum distance between circles
  â”‚    â”‚    â”‚          param1 = param1,
  â”‚    â”‚    â”‚          param2 = param2,
  â”‚    â”‚    â”‚          minRadius = 20,
  â”‚    â”‚    â”‚          maxRadius = 100
  â”‚    â”‚    â”‚        )
  â”‚    â”‚    â”‚    â”œâ”€â–º Collect all detected circles
  â”‚    â”‚    â”‚    â”œâ”€â–º Filter circles with radius 20-80 pixels
  â”‚    â”‚    â”‚    â”œâ”€â–º Count valid circles
  â”‚    â”‚    â”‚    â””â”€â–º If valid_circles > 0:
  â”‚    â”‚    â”‚         confidence = min(0.95, 0.7 + valid_circles * 0.1)
  â”‚    â”‚    â”‚         RETURN (True, confidence)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: (helmet_detected_hough, confidence_hough)
  â”‚    â”‚
  â”‚    â”œâ”€â–º Method 4: Advanced Shape Analysis (Weight: 20%)
  â”‚    â”‚    â”œâ”€â–º Convert to grayscale
  â”‚    â”‚    â”œâ”€â–º Multi-threshold edge detection:
  â”‚    â”‚    â”‚    edges1 = Canny(gray, 30, 90)
  â”‚    â”‚    â”‚    edges2 = Canny(gray, 50, 150)
  â”‚    â”‚    â”‚    edges3 = Canny(gray, 70, 200)
  â”‚    â”‚    â”‚    edges = edges1 | edges2 | edges3
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Morphological closing (5x5 ellipse)
  â”‚    â”‚    â”œâ”€â–º Find contours
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º For each contour:
  â”‚    â”‚    â”‚    â”œâ”€â–º If area > 2000:
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Get bounding box
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Check if in upper 45% of frame
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate perimeter
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate circularity = 4*Ï€*area / perimeterÂ²
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate aspect_ratio = w / h
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate convex hull
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate solidity = area / hull_area
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Fit ellipse to contour
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate ellipse_fit = contour_area / ellipse_area
  â”‚    â”‚    â”‚    â”‚    â”‚
  â”‚    â”‚    â”‚    â”‚    â”œâ”€â–º Calculate composite shape score:
  â”‚    â”‚    â”‚    â”‚    â”‚    score = circularity * 0.35 +
  â”‚    â”‚    â”‚    â”‚    â”‚            solidity * 0.25 +
  â”‚    â”‚    â”‚    â”‚    â”‚            ellipse_fit * 0.25 +
  â”‚    â”‚    â”‚    â”‚    â”‚            (1.0 if 0.7<=aspect_ratio<=1.3 else 0.5) * 0.15
  â”‚    â”‚    â”‚    â”‚    â”‚
  â”‚    â”‚    â”‚    â”‚    â””â”€â–º If score > 0.65:
  â”‚    â”‚    â”‚    â”‚         â””â”€â–º Helmet detected! confidence = score
  â”‚    â”‚    â”‚    â”‚
  â”‚    â”‚    â”‚    â””â”€â–º Result: (helmet_detected_shape, confidence_shape)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: (helmet_detected_shape, best_score)
  â”‚    â”‚
  â”‚    â””â”€â–º Method 5: Edge Feature Analysis (Weight: 10%)
  â”‚         â”œâ”€â–º Convert to grayscale
  â”‚         â”œâ”€â–º Apply bilateral filter (preserve edges)
  â”‚         â”œâ”€â–º Calculate Sobel gradients:
  â”‚         â”‚    sobelx = Sobel(filtered, CV_64F, 1, 0, ksize=3)
  â”‚         â”‚    sobely = Sobel(filtered, CV_64F, 0, 1, ksize=3)
  â”‚         â”‚    magnitude = sqrt(sobelxÂ² + sobelyÂ²)
  â”‚         â”œâ”€â–º Threshold magnitude > 50
  â”‚         â”œâ”€â–º Find contours
  â”‚         â”œâ”€â–º For each contour with area > 1500:
  â”‚         â”‚    â”œâ”€â–º In upper 45% of frame
  â”‚         â”‚    â”œâ”€â–º Calculate circularity
  â”‚         â”‚    â””â”€â–º If circularity > 0.6:
  â”‚         â”‚         â””â”€â–º Helmet detected! confidence = circularity
  â”‚         â”‚
  â”‚         â””â”€â–º Result: (helmet_detected_edge, confidence_edge)
  â”‚
  â”œâ”€â–º Step 2: Ensemble Voting
  â”‚    â”œâ”€â–º Collect all results with weights:
  â”‚    â”‚    detections = [
  â”‚    â”‚      (helmet_color, confidence_color, 0.25),
  â”‚    â”‚      (helmet_template, confidence_template, 0.20),
  â”‚    â”‚      (helmet_hough, confidence_hough, 0.25),
  â”‚    â”‚      (helmet_shape, confidence_shape, 0.20),
  â”‚    â”‚      (helmet_edge, confidence_edge, 0.10)
  â”‚    â”‚    ]
  â”‚    â”‚
  â”‚    â”œâ”€â–º For each detection with confidence > 0.5:
  â”‚    â”‚    total_confidence += confidence * weight
  â”‚    â”‚    detection_votes += 1
  â”‚    â”‚
  â”‚    â”œâ”€â–º Require at least 2 methods to agree:
  â”‚    â”‚    helmet_detected = (detection_votes >= 2) AND (total_confidence > 0.5)
  â”‚    â”‚
  â”‚    â””â”€â–º Final confidence = min(0.95, total_confidence)
  â”‚
  â”œâ”€â–º Step 3: Temporal Consistency
  â”‚    â”œâ”€â–º Append result to helmet_history (max 20 frames)
  â”‚    â”œâ”€â–º If history has >= 10 frames:
  â”‚    â”‚    â”œâ”€â–º Get last 10 detections
  â”‚    â”‚    â”œâ”€â–º Count True detections
  â”‚    â”‚    â”œâ”€â–º If >= 6 out of 10 are True (60% agreement):
  â”‚    â”‚    â”‚    â””â”€â–º RETURN (True, confidence * 1.2)
  â”‚    â”‚    â””â”€â–º If <= 3 out of 10 are True:
  â”‚    â”‚         â””â”€â–º RETURN (False, 0.0)
  â”‚    â”‚
  â”‚    â””â”€â–º Otherwise return current detection result
  â”‚
  â””â”€â–º OUTPUT: (helmet_detected, confidence)
       Example: (True, 0.93) means "Helmet detected with 93% confidence"
```

---

## 4.3 Face Cover Detection Algorithm (Detailed Flow)

```
INPUT: Frame (640x480 BGR image)
  â”‚
  â”œâ”€â–º Step 1: Multi-Cascade Face Detection
  â”‚    â”œâ”€â–º Convert frame to grayscale
  â”‚    â”œâ”€â–º Run 4 different face detection cascades:
  â”‚    â”‚    â”œâ”€â–º Cascade 1: haarcascade_frontalface_default.xml
  â”‚    â”‚    â”‚    faces1 = detectMultiScale(gray, 1.1, 5, minSize=(50,50))
  â”‚    â”‚    â”œâ”€â–º Cascade 2: haarcascade_frontalface_alt.xml
  â”‚    â”‚    â”‚    faces2 = detectMultiScale(gray, 1.1, 5, minSize=(50,50))
  â”‚    â”‚    â”œâ”€â–º Cascade 3: haarcascade_frontalface_alt2.xml
  â”‚    â”‚    â”‚    faces3 = detectMultiScale(gray, 1.1, 5, minSize=(50,50))
  â”‚    â”‚    â””â”€â–º Cascade 4: haarcascade_profileface.xml
  â”‚    â”‚         faces4 = detectMultiScale(gray, 1.1, 5, minSize=(50,50))
  â”‚    â”‚
  â”‚    â”œâ”€â–º Combine all detected faces
  â”‚    â”‚    all_faces = faces1 + faces2 + faces3 + faces4
  â”‚    â”‚
  â”‚    â”œâ”€â–º Apply Non-Maximum Suppression (NMS):
  â”‚    â”‚    â”œâ”€â–º Purpose: Remove duplicate/overlapping face detections
  â”‚    â”‚    â”œâ”€â–º Algorithm:
  â”‚    â”‚    â”‚    1. Calculate areas of all bounding boxes
  â”‚    â”‚    â”‚    2. Sort by area (largest first)
  â”‚    â”‚    â”‚    3. Keep largest box
  â”‚    â”‚    â”‚    4. For remaining boxes:
  â”‚    â”‚    â”‚       - Calculate overlap (IoU) with kept box
  â”‚    â”‚    â”‚       - If overlap > 50%: discard
  â”‚    â”‚    â”‚       - Else: keep
  â”‚    â”‚    â”‚    5. Repeat until all boxes processed
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: unique_faces (no duplicates)
  â”‚    â”‚
  â”‚    â””â”€â–º If no faces detected: RETURN (False, 0.0)
  â”‚
  â”œâ”€â–º Step 2: Analyze Each Detected Face
  â”‚    â”‚
  â”‚    For each face (x, y, w, h):
  â”‚    â”‚
  â”‚    â”œâ”€â–º Extract face region:
  â”‚    â”‚    face_region = frame[y:y+h, x:x+w]
  â”‚    â”‚
  â”‚    â”œâ”€â–º Method 1: Advanced Color Analysis (Weight: 30%)
  â”‚    â”‚    â”œâ”€â–º Convert face to HSV color space
  â”‚    â”‚    â”œâ”€â–º Apply 6 mask color ranges:
  â”‚    â”‚    â”‚    1. Blue Surgical: [100,100,50] to [130,255,200]
  â”‚    â”‚    â”‚    2. White Surgical: [0,0,180] to [180,30,255]
  â”‚    â”‚    â”‚    3. Black Cloth: [0,0,0] to [180,255,50]
  â”‚    â”‚    â”‚    4. Light Blue: [90,50,100] to [110,255,255]
  â”‚    â”‚    â”‚    5. Green Medical: [40,50,50] to [80,255,200]
  â”‚    â”‚    â”‚    6. Gray Cloth: [0,0,50] to [180,50,150]
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Create combined mask (OR all masks)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Calculate full face coverage:
  â”‚    â”‚    â”‚    total_coverage = covered_pixels / total_face_pixels
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Focus on lower 60% of face (mouth/nose area):
  â”‚    â”‚    â”‚    â”œâ”€â–º Extract lower_face = face_region[0.4*h:, :]
  â”‚    â”‚    â”‚    â”œâ”€â–º Apply same mask color ranges
  â”‚    â”‚    â”‚    â””â”€â–º Calculate lower_coverage
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Weight lower face more heavily:
  â”‚    â”‚    â”‚    final_coverage = total_coverage * 0.3 + lower_coverage * 0.7
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º If final_coverage > 0.35 (35% coverage):
  â”‚    â”‚         â””â”€â–º color_score = min(0.98, final_coverage * 1.5)
  â”‚    â”‚
  â”‚    â”œâ”€â–º Method 2: Texture Analysis (Weight: 25%)
  â”‚    â”‚    â”œâ”€â–º Convert face to grayscale
  â”‚    â”‚    â”œâ”€â–º Calculate Local Binary Pattern approximation:
  â”‚    â”‚    â”‚    kernel = [[-1,-1,-1], [-1,8,-1], [-1,-1,-1]]
  â”‚    â”‚    â”‚    texture = filter2D(gray, -1, kernel)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Calculate texture statistics:
  â”‚    â”‚    â”‚    texture_variance = var(texture)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Masks have more uniform texture (lower variance):
  â”‚    â”‚    â”‚    If variance < 150:  texture_score = 0.9
  â”‚    â”‚    â”‚    If variance < 300:  texture_score = 0.7
  â”‚    â”‚    â”‚    If variance < 500:  texture_score = 0.5
  â”‚    â”‚    â”‚    Else:                texture_score = 0.2
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: texture_score
  â”‚    â”‚
  â”‚    â”œâ”€â–º Method 3: Edge Density Analysis (Weight: 20%)
  â”‚    â”‚    â”œâ”€â–º Convert face to grayscale
  â”‚    â”‚    â”œâ”€â–º Multi-scale edge detection:
  â”‚    â”‚    â”‚    edges1 = Canny(gray, 30, 100)
  â”‚    â”‚    â”‚    edges2 = Canny(gray, 50, 150)
  â”‚    â”‚    â”‚    edges = edges1 | edges2
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Calculate edge density:
  â”‚    â”‚    â”‚    edge_density = edge_pixels / total_face_pixels
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Lower density suggests mask (smoother surface):
  â”‚    â”‚    â”‚    If density < 0.08:   edge_score = 0.95
  â”‚    â”‚    â”‚    If density < 0.12:   edge_score = 0.85
  â”‚    â”‚    â”‚    If density < 0.15:   edge_score = 0.65
  â”‚    â”‚    â”‚    Else:                 edge_score = 0.3
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: edge_score
  â”‚    â”‚
  â”‚    â”œâ”€â–º Method 4: Eye Visibility Check (Weight: 10%)
  â”‚    â”‚    â”œâ”€â–º Extract upper 50% of face (eye region)
  â”‚    â”‚    â”œâ”€â–º Run eye cascade detector:
  â”‚    â”‚    â”‚    eyes = eye_cascade.detectMultiScale(upper_face, 1.1, 3)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Interpret results:
  â”‚    â”‚    â”‚    If 0 eyes detected:  eye_score = 0.9  (likely covered)
  â”‚    â”‚    â”‚    If 1 eye detected:   eye_score = 0.6  (partially covered)
  â”‚    â”‚    â”‚    If 2+ eyes detected: eye_score = 0.2  (not covered)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: eye_score
  â”‚    â”‚
  â”‚    â””â”€â–º Method 5: Lower Face Coverage Analysis (Weight: 15%)
  â”‚         â”œâ”€â–º Extract lower 50% of face
  â”‚         â”œâ”€â–º Convert to HSV
  â”‚         â”œâ”€â–º Check for mask colors in lower face
  â”‚         â”œâ”€â–º Calculate coverage ratio
  â”‚         â”œâ”€â–º Calculate color uniformity:
  â”‚         â”‚    uniformity = 1.0 - mean(std_deviation) / 255
  â”‚         â”‚
  â”‚         â”œâ”€â–º Combine coverage and uniformity:
  â”‚         â”‚    score = coverage_ratio * 0.6 + uniformity * 0.4
  â”‚         â”‚
  â”‚         â””â”€â–º If score > 0.5:
  â”‚              â””â”€â–º lower_face_score = min(0.95, score * 1.3)
  â”‚
  â”œâ”€â–º Step 3: Combine All Scores (Weighted Average)
  â”‚    combined_score = (color_score * 0.30 +
  â”‚                     texture_score * 0.25 +
  â”‚                     edge_score * 0.20 +
  â”‚                     eye_score * 0.10 +
  â”‚                     lower_face_score * 0.15)
  â”‚
  â”œâ”€â–º Step 4: Threshold Check
  â”‚    If combined_score > 0.70:  # High threshold for accuracy
  â”‚      face_cover_detected = True
  â”‚      max_confidence = combined_score
  â”‚
  â”œâ”€â–º Step 5: Temporal Consistency
  â”‚    â”œâ”€â–º Append result to face_cover_history (max 20 frames)
  â”‚    â”œâ”€â–º If history has >= 10 frames:
  â”‚    â”‚    â”œâ”€â–º Get last 10 detections
  â”‚    â”‚    â”œâ”€â–º Count True detections
  â”‚    â”‚    â”œâ”€â–º If >= 7 out of 10 are True (70% agreement):
  â”‚    â”‚    â”‚    â””â”€â–º RETURN (True, confidence * 1.1)
  â”‚    â”‚    â””â”€â–º If <= 2 out of 10 are True:
  â”‚    â”‚         â””â”€â–º RETURN (False, 0.0)
  â”‚    â”‚
  â”‚    â””â”€â–º Otherwise return current detection result
  â”‚
  â””â”€â–º OUTPUT: (face_cover_detected, confidence)
       Example: (True, 0.94) means "Face cover detected with 94% confidence"
```

---

## 4.4 Loitering Detection Algorithm (Detailed Flow)

```
INPUT: Frame (640x480 BGR image)
  â”‚
  â”œâ”€â–º Step 1: Motion Detection (Dual Background Subtraction)
  â”‚    â”œâ”€â–º Convert frame to grayscale
  â”‚    â”‚
  â”‚    â”œâ”€â–º Apply MOG2 background subtractor:
  â”‚    â”‚    fg_mask_mog2 = bg_subtractor_mog2.apply(gray)
  â”‚    â”‚    â””â”€â–º Returns: foreground mask (white=motion, black=static)
  â”‚    â”‚
  â”‚    â”œâ”€â–º Apply KNN background subtractor:
  â”‚    â”‚    fg_mask_knn = bg_subtractor_knn.apply(gray)
  â”‚    â”‚    â””â”€â–º Returns: foreground mask
  â”‚    â”‚
  â”‚    â”œâ”€â–º Combine both masks (AND operation for higher accuracy):
  â”‚    â”‚    fg_mask = fg_mask_mog2 AND fg_mask_knn
  â”‚    â”‚    â””â”€â–º Only pixels detected by BOTH methods are considered motion
  â”‚    â”‚
  â”‚    â””â”€â–º Clean the mask:
  â”‚         â”œâ”€â–º Morphological closing (7x7 ellipse) - fill holes
  â”‚         â”œâ”€â–º Morphological opening (7x7 ellipse) - remove noise
  â”‚         â””â”€â–º Result: clean_fg_mask
  â”‚
  â”œâ”€â–º Step 2: Find Motion Regions (Contours)
  â”‚    â”œâ”€â–º Find contours in clean foreground mask
  â”‚    â”‚    contours = findContours(clean_fg_mask, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE)
  â”‚    â”‚
  â”‚    â””â”€â–º Filter significant motion regions (area > 3000 pixels)
  â”‚
  â”œâ”€â–º Step 3: Track Each Moving Object
  â”‚    â”‚
  â”‚    For each significant contour:
  â”‚    â”‚
  â”‚    â”œâ”€â–º Calculate centroid (center point):
  â”‚    â”‚    M = moments(contour)
  â”‚    â”‚    cx = M["m10"] / M["m00"]
  â”‚    â”‚    cy = M["m01"] / M["m00"]
  â”‚    â”‚    Position: (cx, cy)
  â”‚    â”‚
  â”‚    â”œâ”€â–º Find or create tracker for this object:
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Search existing trackers:
  â”‚    â”‚    â”‚    For each existing tracker:
  â”‚    â”‚    â”‚      â”œâ”€â–º Get last known position
  â”‚    â”‚    â”‚      â”œâ”€â–º Calculate distance to current position:
  â”‚    â”‚    â”‚      â”‚    distance = sqrt((cx - last_x)Â² + (cy - last_y)Â²)
  â”‚    â”‚    â”‚      â”œâ”€â–º Check time since last update
  â”‚    â”‚    â”‚      â””â”€â–º If distance < 80 pixels AND time_gap < 5 seconds:
  â”‚    â”‚    â”‚           â””â”€â–º Match found! Use this tracker
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º If no match found:
  â”‚    â”‚         â”œâ”€â–º Create new tracker with unique ID:
  â”‚    â”‚         â”‚    tracker_id = "tracker_{timestamp}_{cx}_{cy}"
  â”‚    â”‚         â”‚    tracker = {
  â”‚    â”‚         â”‚      'positions': deque(maxlen=50),  # Last 50 positions
  â”‚    â”‚         â”‚      'start_time': current_time,
  â”‚    â”‚         â”‚      'timestamps': deque(maxlen=50)
  â”‚    â”‚         â”‚    }
  â”‚    â”‚         â”‚
  â”‚    â”‚         â””â”€â–º Add to loitering_tracker dictionary
  â”‚    â”‚
  â”‚    â”œâ”€â–º Update tracker:
  â”‚    â”‚    tracker['positions'].append((cx, cy))
  â”‚    â”‚    tracker['timestamps'].append(current_time)
  â”‚    â”‚
  â”‚    â””â”€â–º Analyze for loitering:
  â”‚         â”‚
  â”‚         If tracker has >= 15 position records:
  â”‚         â”‚
  â”‚         â”œâ”€â–º Get last 15 positions as numpy array
  â”‚         â”‚    positions = array(last_15_positions)
  â”‚         â”‚    Example: [[100,200], [102,201], [101,200], ...]
  â”‚         â”‚
  â”‚         â”œâ”€â–º Calculate movement statistics:
  â”‚         â”‚    â”œâ”€â–º Calculate variance in X direction: var(positions[:, 0])
  â”‚         â”‚    â”œâ”€â–º Calculate variance in Y direction: var(positions[:, 1])
  â”‚         â”‚    â””â”€â–º Total variance = var_x + var_y
  â”‚         â”‚
  â”‚         â”œâ”€â–º Calculate time elapsed:
  â”‚         â”‚    elapsed_time = current_time - tracker['start_time']
  â”‚         â”‚
  â”‚         â”œâ”€â–º Check loitering conditions:
  â”‚         â”‚    If total_variance < 200 (very little movement)
  â”‚         â”‚    AND elapsed_time > 25 seconds:
  â”‚         â”‚      â””â”€â–º LOITERING DETECTED!
  â”‚         â”‚           â”œâ”€â–º Calculate confidence:
  â”‚         â”‚           â”‚    confidence = min(0.98, 0.7 + elapsed_time/100)
  â”‚         â”‚           â”‚    â””â”€â–º Longer loitering = higher confidence
  â”‚         â”‚           â”‚
  â”‚         â”‚           â””â”€â–º RETURN (True, confidence)
  â”‚         â”‚
  â”‚         â””â”€â–º Example analysis:
  â”‚              Positions: [(100,200), (101,201), (100,200), (102,199), ...]
  â”‚              Variance: 15 (very low - almost stationary)
  â”‚              Time: 35 seconds
  â”‚              â†’ LOITERING DETECTED (confidence: 0.85)
  â”‚
  â”œâ”€â–º Step 4: Cleanup Old Trackers
  â”‚    â”œâ”€â–º For each tracker in dictionary:
  â”‚    â”‚    â”œâ”€â–º Check time since last update
  â”‚    â”‚    â””â”€â–º If not updated for > 180 seconds:
  â”‚    â”‚         â””â”€â–º Remove tracker (person left the scene)
  â”‚    â”‚
  â”‚    â””â”€â–º Purpose: Prevent memory buildup from stale trackers
  â”‚
  â””â”€â–º OUTPUT: (loitering_detected, confidence)
       Example: (True, 0.92) means "Loitering detected with 92% confidence"
       
       If multiple people present, returns True if ANY person is loitering
```

---

## 4.5 Posture Detection Algorithm (Detailed Flow)

```
INPUT: Frame (640x480 BGR image)
  â”‚
  â”œâ”€â–º Step 0: Pre-check
  â”‚    â”œâ”€â–º Run people detection first
  â”‚    â””â”€â–º If no people detected: RETURN (False, 0.0)
  â”‚
  â”œâ”€â–º Step 1: Multi-scale Edge Detection
  â”‚    â”œâ”€â–º Convert frame to grayscale
  â”‚    â”œâ”€â–º Apply Canny edge detection with 3 different thresholds:
  â”‚    â”‚    edges1 = Canny(gray, 20, 80)   # Low threshold - catch weak edges
  â”‚    â”‚    edges2 = Canny(gray, 40, 120)  # Medium threshold
  â”‚    â”‚    edges3 = Canny(gray, 60, 180)  # High threshold - strong edges only
  â”‚    â”‚
  â”‚    â”œâ”€â–º Combine all edge maps:
  â”‚    â”‚    edges = edges1 | edges2 | edges3
  â”‚    â”‚    â””â”€â–º Result: comprehensive edge map
  â”‚    â”‚
  â”‚    â””â”€â–º Morphological closing (3x3 kernel):
  â”‚         â””â”€â–º Connect nearby edges to form complete body contours
  â”‚
  â”œâ”€â–º Step 2: Find and Analyze Body Contours
  â”‚    â”œâ”€â–º Find contours in edge map
  â”‚    â”‚    contours = findContours(edges, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE)
  â”‚    â”‚
  â”‚    â””â”€â–º Filter significant contours (area > 3500 pixels)
  â”‚
  â”œâ”€â–º Step 3: Analyze Each Person-Like Contour
  â”‚    â”‚
  â”‚    For each significant contour:
  â”‚    â”‚
  â”‚    â”œâ”€â–º Get bounding rectangle:
  â”‚    â”‚    x, y, w, h = boundingRect(contour)
  â”‚    â”‚
  â”‚    â”œâ”€â–º Calculate aspect ratio:
  â”‚    â”‚    aspect_ratio = h / w
  â”‚    â”‚
  â”‚    â”œâ”€â–º Check if person-like shape:
  â”‚    â”‚    If aspect_ratio > 1.5 AND h > 120 pixels:
  â”‚    â”‚      â””â”€â–º Likely a person, continue analysis
  â”‚    â”‚
  â”‚    â”œâ”€â–º Component 1: Solidity Analysis (Weight: 30%)
  â”‚    â”‚    â”œâ”€â–º Calculate convex hull of contour:
  â”‚    â”‚    â”‚    hull = convexHull(contour)
  â”‚    â”‚    â”‚    hull_area = contourArea(hull)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Calculate solidity:
  â”‚    â”‚    â”‚    solidity = contour_area / hull_area
  â”‚    â”‚    â”‚    â””â”€â–º Measures how "solid" vs "fragmented" the shape is
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Interpret solidity:
  â”‚    â”‚         If solidity > 0.8:  score = 0.9  (very solid - good posture)
  â”‚    â”‚         If solidity > 0.7:  score = 0.7  (good posture)
  â”‚    â”‚         If solidity > 0.5:  score = 0.5  (moderate posture)
  â”‚    â”‚         Else:                score = 0.2  (poor posture - fragmented shape)
  â”‚    â”‚
  â”‚    â”œâ”€â–º Component 2: Verticality Check (Weight: 25%)
  â”‚    â”‚    â”œâ”€â–º Calculate image moments:
  â”‚    â”‚    â”‚    moments = moments(contour)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Calculate orientation angle:
  â”‚    â”‚    â”‚    orientation = 0.5 * arctan2(2*mu11, mu20 - mu02)
  â”‚    â”‚    â”‚    â””â”€â–º Result in radians (-Ï€/2 to Ï€/2)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Calculate verticality score:
  â”‚    â”‚    â”‚    verticality = 1.0 - |orientation| / (Ï€/2)
  â”‚    â”‚    â”‚    â””â”€â–º 1.0 = perfectly vertical
  â”‚    â”‚    â”‚        0.0 = perfectly horizontal
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Example:
  â”‚    â”‚         Upright person: orientation â‰ˆ 0Â°  â†’ verticality = 1.0
  â”‚    â”‚         Leaning person: orientation â‰ˆ 30Â° â†’ verticality = 0.67
  â”‚    â”‚         Horizontal: orientation â‰ˆ 90Â°     â†’ verticality = 0.0
  â”‚    â”‚
  â”‚    â”œâ”€â–º Component 3: Aspect Ratio Score (Weight: 20%)
  â”‚    â”‚    â”œâ”€â–º Good posture typically has aspect ratio 2-4 (tall, narrow)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Score based on aspect ratio:
  â”‚    â”‚         If 2.0 <= aspect_ratio <= 4.0:  score = 0.9
  â”‚    â”‚         If 1.5 <= aspect_ratio < 2.0:   score = 0.7
  â”‚    â”‚         If 4.0 < aspect_ratio <= 5.0:   score = 0.7
  â”‚    â”‚         Else:                            score = 0.4
  â”‚    â”‚
  â”‚    â”œâ”€â–º Component 4: Balance Analysis (Weight: 15%)
  â”‚    â”‚    â”œâ”€â–º Divide contour into upper and lower halves:
  â”‚    â”‚    â”‚    midpoint_y = y + h/2
  â”‚    â”‚    â”‚    upper_half = contour points where y < midpoint_y
  â”‚    â”‚    â”‚    lower_half = contour points where y >= midpoint_y
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Calculate areas (if possible):
  â”‚    â”‚    â”‚    upper_area = contourArea(upper_half)
  â”‚    â”‚    â”‚    lower_area = contourArea(lower_half)
  â”‚    â”‚    â”‚
  â”‚    â”‚    â”œâ”€â–º Calculate balance ratio:
  â”‚    â”‚    â”‚    balance = min(upper_area/lower_area, lower_area/upper_area)
  â”‚    â”‚    â”‚    â””â”€â–º Values close to 1.0 indicate good balance
  â”‚    â”‚    â”‚
  â”‚    â”‚    â””â”€â–º Result: balance_score = balance
  â”‚    â”‚
  â”‚    â””â”€â–º Component 5: Symmetry Check (Weight: 10%)
  â”‚         â”œâ”€â–º Divide contour into left and right halves:
  â”‚         â”‚    midpoint_x = x + w/2
  â”‚         â”‚    left_half = contour points where x < midpoint_x
  â”‚         â”‚    right_half = contour points where x >= midpoint_x
  â”‚         â”‚
  â”‚         â”œâ”€â–º Calculate areas:
  â”‚         â”‚    left_area = contourArea(left_half)
  â”‚         â”‚    right_area = contourArea(right_half)
  â”‚         â”‚
  â”‚         â”œâ”€â–º Calculate symmetry ratio:
  â”‚         â”‚    symmetry = min(left_area/right_area, right_area/left_area)
  â”‚         â”‚    â””â”€â–º Values close to 1.0 indicate good symmetry
  â”‚         â”‚
  â”‚         â””â”€â–º Result: symmetry_score = symmetry
  â”‚
  â”œâ”€â–º Step 4: Calculate Composite Posture Score
  â”‚    composite_score = (solidity * 0.30 +
  â”‚                      verticality * 0.25 +
  â”‚                      aspect_score * 0.20 +
  â”‚                      balance * 0.15 +
  â”‚                      symmetry * 0.10)
  â”‚
  â”‚    Example calculation:
  â”‚      solidity = 0.75    Ã— 0.30 = 0.225
  â”‚      verticality = 0.90 Ã— 0.25 = 0.225
  â”‚      aspect_score = 0.9 Ã— 0.20 = 0.180
  â”‚      balance = 0.85     Ã— 0.15 = 0.128
  â”‚      symmetry = 0.80    Ã— 0.10 = 0.080
  â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”‚      Composite score = 0.838 (good posture)
  â”‚
  â”œâ”€â–º Step 5: Store in History
  â”‚    posture_history.append(composite_score)
  â”‚    â””â”€â–º Keep last 30 scores
  â”‚
  â”œâ”€â–º Step 6: Temporal Smoothing
  â”‚    â”‚
  â”‚    If history has >= 15 frames:
  â”‚    â”‚
  â”‚    â”œâ”€â–º Calculate 15-frame moving average:
  â”‚    â”‚    recent_scores = last_15_scores
  â”‚    â”‚    smoothed_score = sum(recent_scores) / 15
  â”‚    â”‚
  â”‚    â”œâ”€â–º Check threshold:
  â”‚    â”‚    If smoothed_score < 0.45:  # Strict threshold
  â”‚    â”‚      â””â”€â–º Bad posture detected!
  â”‚    â”‚           confidence = 1.0 - smoothed_score
  â”‚    â”‚           â””â”€â–º Lower score = higher confidence of bad posture
  â”‚    â”‚
  â”‚    â””â”€â–º Example:
  â”‚         Recent scores: [0.35, 0.38, 0.40, 0.37, 0.36, ...]
  â”‚         Smoothed: 0.37 (< 0.45 threshold)
  â”‚         â†’ BAD POSTURE DETECTED (confidence: 0.63)
  â”‚
  â””â”€â–º OUTPUT: (bad_posture_detected, confidence)
       Example: (True, 0.91) means "Bad posture detected with 91% confidence"
```

---

*[Continued in DATABASE_QUERIES.md for database operations...]*

